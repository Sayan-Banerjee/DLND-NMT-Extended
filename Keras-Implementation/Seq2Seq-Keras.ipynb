{"nbformat":4,"nbformat_minor":0,"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"name":"Seq2Seq-Keras.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"IXPbiljjDx59","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1598483891574,"user_tz":300,"elapsed":18764,"user":{"displayName":"Sayan Banerjee","photoUrl":"","userId":"02626513484775076634"}},"outputId":"b1890c45-00b8-41a0-9bb5-653a6a744d0a"},"source":["from google.colab import drive\n","import os\n","drive.mount('/content/drive/')\n","os.chdir(\"drive/My Drive/Google_Colab_Drive/Keras-Implementation\")"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fsVrOfvkDvaK","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598483898409,"user_tz":300,"elapsed":2654,"user":{"displayName":"Sayan Banerjee","photoUrl":"","userId":"02626513484775076634"}}},"source":["import collections\n","import helper\n","import numpy as np\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Model\n","from keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional\n","from keras.layers.embeddings import Embedding\n","from keras.optimizers import Adam\n","from keras.losses import sparse_categorical_crossentropy"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"p4xG0A31DvaO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598483902507,"user_tz":300,"elapsed":2011,"user":{"displayName":"Sayan Banerjee","photoUrl":"","userId":"02626513484775076634"}},"outputId":"14ec8c4d-0542-404d-d3c6-e567c304591f"},"source":["# Load English data\n","english_sentences = helper.load_data('data-new/small_vocab_en')\n","# Load French data\n","french_sentences = helper.load_data('data-new/small_vocab_fr')\n","\n","print('Dataset Loaded')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Dataset Loaded\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"41Q72GhUDvaS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1598483905309,"user_tz":300,"elapsed":377,"user":{"displayName":"Sayan Banerjee","photoUrl":"","userId":"02626513484775076634"}},"outputId":"06cb9bef-849a-41b9-d376-2cfc1e57d1b7"},"source":["for sample_i in range(2):\n","    print('small_vocab_en Line {}:  {}'.format(sample_i + 1, english_sentences[sample_i]))\n","    print('small_vocab_fr Line {}:  {}'.format(sample_i + 1, french_sentences[sample_i]))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["small_vocab_en Line 1:  new jersey is sometimes quiet during autumn , and it is snowy in april .\n","small_vocab_fr Line 1:  new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n","small_vocab_en Line 2:  the united states is usually chilly during july , and it is usually freezing in november .\n","small_vocab_fr Line 2:  les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cY10FwaPDvaU","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598483906978,"user_tz":300,"elapsed":571,"user":{"displayName":"Sayan Banerjee","photoUrl":"","userId":"02626513484775076634"}}},"source":[""],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"wi8NN7SyDvaX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598483907161,"user_tz":300,"elapsed":582,"user":{"displayName":"Sayan Banerjee","photoUrl":"","userId":"02626513484775076634"}}},"source":["target_texts = []\n","target_texts_inputs = []\n","for s in french_sentences:\n","    target_text = s + ' <eos>'\n","    target_text_input = '<sos> ' + s\n","    target_texts.append(target_text)\n","    target_texts_inputs.append(target_text_input)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"UCid5bvYDvaZ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598483907162,"user_tz":300,"elapsed":431,"user":{"displayName":"Sayan Banerjee","photoUrl":"","userId":"02626513484775076634"}}},"source":[""],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"-xlxCgwDDvac","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598483910802,"user_tz":300,"elapsed":3899,"user":{"displayName":"Sayan Banerjee","photoUrl":"","userId":"02626513484775076634"}}},"source":["# tokenize the inputs\n","tokenizer_inputs = Tokenizer()\n","tokenizer_inputs.fit_on_texts(english_sentences)\n","input_sequences = tokenizer_inputs.texts_to_sequences(english_sentences)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"uatyL1EpDvae","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598483910806,"user_tz":300,"elapsed":1546,"user":{"displayName":"Sayan Banerjee","photoUrl":"","userId":"02626513484775076634"}},"outputId":"35545241-5396-45d2-fc8e-70bbce765ec6"},"source":["# get the word to index mapping for input language\n","word2idx_inputs = tokenizer_inputs.word_index\n","print('Found %s unique input tokens.' % len(word2idx_inputs))\n","\n","# store number of input words for later\n","# remember to add 1 since indexing starts at 1\n","num_words_input = len(word2idx_inputs) + 1"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Found 199 unique input tokens.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pOaQGy_yDvah","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598483910807,"user_tz":300,"elapsed":1386,"user":{"displayName":"Sayan Banerjee","photoUrl":"","userId":"02626513484775076634"}}},"source":[""],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"q0JaQd0hDvaj","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598483918269,"user_tz":300,"elapsed":8682,"user":{"displayName":"Sayan Banerjee","photoUrl":"","userId":"02626513484775076634"}}},"source":["# tokenize the outputs\n","# don't filter out special characters\n","# otherwise <sos> and <eos> won't appear\n","tokenizer_outputs = Tokenizer(filters='')\n","tokenizer_outputs.fit_on_texts(target_texts + target_texts_inputs) # inefficient, oh well\n","target_sequences = tokenizer_outputs.texts_to_sequences(target_texts)\n","target_sequences_inputs = tokenizer_outputs.texts_to_sequences(target_texts_inputs)\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"3PzASR1MDval","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598483918270,"user_tz":300,"elapsed":8076,"user":{"displayName":"Sayan Banerjee","photoUrl":"","userId":"02626513484775076634"}},"outputId":"e2bb195f-4ff1-4650-9440-f2e2414fda17"},"source":["# get the word to index mapping for output language\n","word2idx_outputs = tokenizer_outputs.word_index\n","print('Found %s unique output tokens.' % len(word2idx_outputs))\n","# store number of output words for later\n","# remember to add 1 since indexing starts at 1\n","num_words_output = len(word2idx_outputs) + 1"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Found 356 unique output tokens.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RKw1t4xqDvan","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598483926513,"user_tz":300,"elapsed":380,"user":{"displayName":"Sayan Banerjee","photoUrl":"","userId":"02626513484775076634"}}},"source":[""],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"nEyhAgN1Dvaq","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598483927229,"user_tz":300,"elapsed":544,"user":{"displayName":"Sayan Banerjee","photoUrl":"","userId":"02626513484775076634"}}},"source":["\n","# determine maximum length input sequence\n","max_len_input = max(len(s) for s in input_sequences)\n","\n","# determine maximum length output sequence\n","max_len_target = max(len(s) for s in target_sequences)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"5QuRHfH8Dvas","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":170},"executionInfo":{"status":"ok","timestamp":1598483929577,"user_tz":300,"elapsed":2044,"user":{"displayName":"Sayan Banerjee","photoUrl":"","userId":"02626513484775076634"}},"outputId":"5c2be948-9ed6-41e1-d897-624d5f909826"},"source":["# pad the sequences\n","encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_input, padding='pre')\n","print(\"encoder_inputs.shape:\", encoder_inputs.shape)\n","print(\"encoder_inputs[0]:\", encoder_inputs[0])\n","\n","decoder_inputs = pad_sequences(target_sequences_inputs, maxlen=max_len_target, padding='post')\n","print(\"decoder_inputs[0]:\", decoder_inputs[0])\n","print(\"decoder_inputs.shape:\", decoder_inputs.shape)\n","\n","decoder_targets = pad_sequences(target_sequences, maxlen=max_len_target, padding='post')\n","print(\"decoder_targets[0]:\", decoder_targets[0])\n","print(\"decoder_targets.shape:\", decoder_targets.shape)\n","\n","# Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n","decoder_targets = decoder_targets.reshape(*decoder_targets.shape, 1)\n","print(\"After reshaping, decoder_targets.shape:\", decoder_targets.shape)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["encoder_inputs.shape: (137861, 15)\n","encoder_inputs[0]: [ 0  0 17 23  1  8 67  4 39  7  3  1 55  2 44]\n","decoder_inputs[0]: [  7  38  37   1  12  70  40  15  28   3  10   5   1 115   4  53   2   0\n","   0   0   0   0   0   0]\n","decoder_inputs.shape: (137861, 24)\n","decoder_targets[0]: [ 38  37   1  12  70  40  15  28   3  10   5   1 115   4  53   2   6   0\n","   0   0   0   0   0   0]\n","decoder_targets.shape: (137861, 24)\n","After reshaping, decoder_targets.shape: (137861, 24, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OOuHlMZ8Dvau","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598483931533,"user_tz":300,"elapsed":375,"user":{"displayName":"Sayan Banerjee","photoUrl":"","userId":"02626513484775076634"}}},"source":["def encdec_model(input_sequence_length, output_sequence_length, english_vocab_size, french_vocab_size):\n","    \"\"\"\n","    Build and train an encoder-decoder model on x and y\n","    :param input_shape: Tuple of input shape\n","    :param output_sequence_length: Length of output sequence\n","    :param english_vocab_size: Number of unique English words in the dataset\n","    :param french_vocab_size: Number of unique French words in the dataset\n","    :return: Keras model built, but not trained\n","    \"\"\"\n","    # OPTIONAL: Implement\n","    dropout = 0.5\n","    embeddim = 200\n","    outputdim = french_vocab_size\n","    rnnunits = 128\n","    input_sequence = Input(shape=(input_sequence_length,))\n","    embedding_layer = Embedding(\n","                      english_vocab_size,\n","                      embeddim,\n","                      embeddings_initializer=\"glorot_normal\",\n","                      input_length=input_sequence_length,\n","                      trainable=True\n","                        )\n","    x = embedding_layer(input_sequence)\n","    encoder = GRU(units=rnnunits, return_state=True, dropout=dropout)\n","    \n","    encoder_outputs, state_h = encoder(x)\n","    encoder_states = [state_h]\n","    decoder_inputs = Input(shape=(output_sequence_length,))\n","    decoder_embedding = Embedding(french_vocab_size, embeddim,\n","                                  embeddings_initializer=\"glorot_normal\",\n","                                  trainable = True)\n","    decoder_inputs_x = decoder_embedding(decoder_inputs)\n","    decoder_gru = GRU(rnnunits, return_sequences=True, return_state=True, dropout=dropout)\n","    decoder_outputs, _ = decoder_gru(decoder_inputs_x, initial_state=encoder_states)\n","    decoder_dense = Dense(units=outputdim, activation='softmax')\n","    logits = decoder_dense(decoder_outputs)\n","    model = Model([input_sequence, decoder_inputs], logits)\n","    model.compile(loss=sparse_categorical_crossentropy,\n","                  optimizer=Adam(lr=1e-3),\n","                  metrics=['accuracy'])\n","    return model, input_sequence, encoder_states, decoder_embedding, decoder_gru, decoder_dense\n"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ch2BcpmvDvaw","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598483933085,"user_tz":300,"elapsed":1295,"user":{"displayName":"Sayan Banerjee","photoUrl":"","userId":"02626513484775076634"}}},"source":["model, input_sequence, encoder_states, decoder_embedding, decoder_gru, decoder_dense =\\\n","                                                                encdec_model(input_sequence_length = max_len_input,\n","                                                                output_sequence_length= max_len_target,\n","                                                                english_vocab_size = num_words_input,\n","                                                                french_vocab_size = num_words_output)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"IP5TFIkXDvay","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":697},"executionInfo":{"status":"ok","timestamp":1598487534127,"user_tz":300,"elapsed":3601393,"user":{"displayName":"Sayan Banerjee","photoUrl":"","userId":"02626513484775076634"}},"outputId":"1d3d7585-918d-409a-e40a-e960a97306e7"},"source":["r = model.fit(\n","  [encoder_inputs, decoder_inputs], decoder_targets,\n","  batch_size=128,\n","  epochs=20,\n","  validation_split=0.2,\n",")"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","862/862 [==============================] - 179s 208ms/step - loss: 1.0251 - accuracy: 0.7334 - val_loss: 0.5100 - val_accuracy: 0.8279\n","Epoch 2/20\n","862/862 [==============================] - 176s 205ms/step - loss: 0.4354 - accuracy: 0.8505 - val_loss: 0.3570 - val_accuracy: 0.8765\n","Epoch 3/20\n","862/862 [==============================] - 180s 208ms/step - loss: 0.3176 - accuracy: 0.8891 - val_loss: 0.2683 - val_accuracy: 0.9061\n","Epoch 4/20\n","862/862 [==============================] - 179s 208ms/step - loss: 0.2563 - accuracy: 0.9084 - val_loss: 0.2251 - val_accuracy: 0.9198\n","Epoch 5/20\n","862/862 [==============================] - 176s 205ms/step - loss: 0.2228 - accuracy: 0.9202 - val_loss: 0.1994 - val_accuracy: 0.9303\n","Epoch 6/20\n","862/862 [==============================] - 176s 205ms/step - loss: 0.1888 - accuracy: 0.9339 - val_loss: 0.1611 - val_accuracy: 0.9444\n","Epoch 7/20\n","862/862 [==============================] - 179s 208ms/step - loss: 0.1573 - accuracy: 0.9454 - val_loss: 0.1358 - val_accuracy: 0.9536\n","Epoch 8/20\n","862/862 [==============================] - 182s 211ms/step - loss: 0.1349 - accuracy: 0.9540 - val_loss: 0.1175 - val_accuracy: 0.9615\n","Epoch 9/20\n","862/862 [==============================] - 182s 211ms/step - loss: 0.1170 - accuracy: 0.9618 - val_loss: 0.1015 - val_accuracy: 0.9682\n","Epoch 10/20\n","862/862 [==============================] - 181s 211ms/step - loss: 0.1026 - accuracy: 0.9668 - val_loss: 0.0917 - val_accuracy: 0.9703\n","Epoch 11/20\n","862/862 [==============================] - 181s 210ms/step - loss: 0.0949 - accuracy: 0.9688 - val_loss: 0.0863 - val_accuracy: 0.9713\n","Epoch 12/20\n","862/862 [==============================] - 181s 210ms/step - loss: 0.0900 - accuracy: 0.9700 - val_loss: 0.0842 - val_accuracy: 0.9717\n","Epoch 13/20\n","862/862 [==============================] - 181s 210ms/step - loss: 0.0774 - accuracy: 0.9724 - val_loss: 0.0544 - val_accuracy: 0.9795\n","Epoch 14/20\n","862/862 [==============================] - 180s 208ms/step - loss: 0.0550 - accuracy: 0.9790 - val_loss: 0.0428 - val_accuracy: 0.9850\n","Epoch 15/20\n","862/862 [==============================] - 181s 211ms/step - loss: 0.0467 - accuracy: 0.9821 - val_loss: 0.0380 - val_accuracy: 0.9873\n","Epoch 16/20\n","862/862 [==============================] - 181s 210ms/step - loss: 0.0419 - accuracy: 0.9843 - val_loss: 0.0340 - val_accuracy: 0.9890\n","Epoch 17/20\n","862/862 [==============================] - 179s 208ms/step - loss: 0.0384 - accuracy: 0.9855 - val_loss: 0.0318 - val_accuracy: 0.9891\n","Epoch 18/20\n","862/862 [==============================] - 180s 208ms/step - loss: 0.0355 - accuracy: 0.9867 - val_loss: 0.0293 - val_accuracy: 0.9898\n","Epoch 19/20\n","862/862 [==============================] - 179s 208ms/step - loss: 0.0334 - accuracy: 0.9873 - val_loss: 0.0277 - val_accuracy: 0.9902\n","Epoch 20/20\n","862/862 [==============================] - 178s 207ms/step - loss: 0.0319 - accuracy: 0.9879 - val_loss: 0.0264 - val_accuracy: 0.9906\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"l3N5YLDeDva1","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KkTz6rdoDva7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598488051352,"user_tz":300,"elapsed":724,"user":{"displayName":"Sayan Banerjee","photoUrl":"","userId":"02626513484775076634"}}},"source":["# Save model\n","model.save('seq2seq.h5')"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"c0ZhbauiDva9","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598488051359,"user_tz":300,"elapsed":294,"user":{"displayName":"Sayan Banerjee","photoUrl":"","userId":"02626513484775076634"}}},"source":[""],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"6kSziX6CDva_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598488052285,"user_tz":300,"elapsed":641,"user":{"displayName":"Sayan Banerjee","photoUrl":"","userId":"02626513484775076634"}},"outputId":"329ebc53-0ff9-4a1c-d1de-75979fdfa4aa"},"source":["##### Make predictions #####\n","# We need to create another model\n","# that can take in the RNN state and previous word as input\n","# and accept a T=1 sequence.\n","\n","# The encoder will be stand-alone\n","# From this we will get our initial decoder hidden state\n","rnnunits = 128\n","encoder_model = Model(input_sequence, encoder_states)\n","\n","decoder_state_input_h = Input(shape=(rnnunits,))\n","\n","decoder_states_inputs = [decoder_state_input_h]\n","\n","decoder_inputs_single = Input(shape=(1,))\n","decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)\n","\n","# this time, we want to keep the states too, to be output\n","# by our sampling model\n","\n","decoder_outputs, state_h = decoder_gru(\n","  decoder_inputs_single_x,\n","  initial_state=decoder_states_inputs\n",") \n","decoder_states = [state_h]\n","print(decoder_outputs.shape)\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","# The sampling model\n","# inputs: y(t-1), h(t-1), c(t-1)\n","# outputs: y(t), h(t), c(t)\n","decoder_model = Model(\n","  [decoder_inputs_single] + decoder_states_inputs, \n","  [decoder_outputs] + decoder_states\n",")\n","\n","# map indexes back into real words\n","# so we can view the results\n","idx2word_eng = {v:k for k, v in word2idx_inputs.items()}\n","idx2word_trans = {v:k for k, v in word2idx_outputs.items()}\n"],"execution_count":16,"outputs":[{"output_type":"stream","text":["(None, 1, 128)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e0VTGbUbDvbC","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598488053438,"user_tz":300,"elapsed":366,"user":{"displayName":"Sayan Banerjee","photoUrl":"","userId":"02626513484775076634"}}},"source":["def decode_sequence(input_seq):\n","    # Encode the input as state vectors.\n","    states_value = encoder_model.predict(input_seq)\n","    states_value = [states_value]\n","\n","    # Populate the first character of target sequence with the start character.\n","    # NOTE: tokenizer lower-cases all words\n","    idx = word2idx_outputs['<sos>']\n","    \n","    # if we get this we break\n","    eos = word2idx_outputs['<eos>']\n","\n","    # Create the translation\n","    output_sentence = []\n","    for _ in range(max_len_target):\n","        target_seq = np.zeros((1, 1))\n","        target_seq[0, 0] = idx\n","        \n","        output_tokens, h = decoder_model.predict([target_seq] + states_value)\n","        # Get next word\n","        idx = np.argmax(output_tokens[0, 0, :])\n","\n","        # End sentence of EOS\n","        if eos == idx:\n","            break\n","\n","        word = ''\n","        if idx > 0:\n","            word = idx2word_trans[idx]\n","            output_sentence.append(word)\n","\n","\n","        # Update states\n","        states_value = [h]\n","        \n","\n","    return ' '.join(output_sentence)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"OwmzWt2xDvbE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":697},"executionInfo":{"status":"ok","timestamp":1598488169305,"user_tz":300,"elapsed":115006,"user":{"displayName":"Sayan Banerjee","photoUrl":"","userId":"02626513484775076634"}},"outputId":"510b8964-b21b-433a-e6f2-33a07363ed12"},"source":["while True:\n","  # Do some test translations\n","    i = np.random.choice(len(english_sentences))\n","    input_seq = encoder_inputs[i:i+1]\n","    translation = decode_sequence(input_seq)\n","    print('-')\n","    print('Input:', english_sentences[i])\n","    print('Translation:', translation)\n","\n","    ans = input(\"Continue? [Y/n]\")\n","    if ans and ans.lower().startswith('n'):\n","        break\n"],"execution_count":18,"outputs":[{"output_type":"stream","text":["-\n","Input: new jersey is dry during april , but it is usually hot in september .\n","Translation: new jersey est sec en avril , mais il est généralement chaud en septembre .\n","Continue? [Y/n]y\n","-\n","Input: their favorite fruit is the banana , but your favorite is the grapefruit .\n","Translation: leur fruit préféré est la banane , mais votre favori est le pamplemousse .\n","Continue? [Y/n]y\n","-\n","Input: i like peaches , mangoes , and grapes .\n","Translation: j'aime les pêches , les mangues et les raisins .\n","Continue? [Y/n]y\n","-\n","Input: new jersey is never hot during december , and it is sometimes cold in fall .\n","Translation: new jersey est jamais chaude en décembre , et il est parfois froid à l' automne .\n","Continue? [Y/n]y\n","-\n","Input: china is sometimes chilly during april , but it is usually nice in autumn .\n","Translation: la chine est parfois froid en avril , mais il est généralement agréable à l' automne .\n","Continue? [Y/n]y\n","-\n","Input: china is never pleasant during summer , and it is usually rainy in june .\n","Translation: chine est jamais agréable en été , et il est généralement pluvieux en juillet .\n","Continue? [Y/n]y\n","-\n","Input: the peach is our least favorite fruit , but the mango is their least favorite .\n","Translation: la pêche est notre fruit préféré moins , mais la mangue est leur moins préférée .\n","Continue? [Y/n]y\n","-\n","Input: india is usually wet during october , but it is sometimes pleasant in july .\n","Translation: l' inde est généralement humide en octobre , mais il est parfois agréable en janvier .\n","Continue? [Y/n]y\n","-\n","Input: the peach is her most loved fruit , but the mango is their most loved .\n","Translation: la pêche est son fruit le plus aimé , mais la mangue est leur plus aimé .\n","Continue? [Y/n]y\n","-\n","Input: new jersey is usually nice during june , but it is usually freezing in december .\n","Translation: new jersey est généralement agréable en juin , mais il gèle habituellement en décembre .\n","Continue? [Y/n]n\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XBye4sKRDvbG","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}